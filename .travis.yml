sudo: false
dist: trusty
language: scala
scala:
  - 2.11.8
before_install:
  - python -V
  - pip -V
  - pip install six dill
script:
  - jdk_switcher use openjdk8
  - sbt spDist
  - sbt spPublishLocal
  # Install a version of Spark to test this against
  - wget http://d3kbcqa49mib13.cloudfront.net/spark-2.0.2-bin-hadoop2.7.tgz
  - tar xf spark-2.0.2-bin-hadoop2.7.tgz
  # TODO make this less fragile.
  - export SPARK_PACKAGE_JAR=`ls $(pwd)/target/scala-2.11/spark-jython-udf-assembly*.jar`
  - echo $SPARK_PACKAGE_JAR
  # Ensure that we have our python package on our classpath for now
  - export PYTHONPATH="$(pwd)/python:$PYTHONPATH"
  - spark-2.0.2-bin-hadoop2.7/bin/spark-submit --jars file://$SPARK_PACKAGE_JAR examples/jython_udf_perf.py examples/jython_udf_perf.py 1 1
  
# Cache these at the end of the build
cache:
  directories:
    - $HOME/.ivy2/cache
    - $HOME/.sbt/boot/
